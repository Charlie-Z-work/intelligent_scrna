import numpy as np
from sklearn.metrics import pairwise_distances as pair
from sklearn.preprocessing import normalize
import os

# ç¡®ä¿graphç›®å½•å­˜åœ¨
os.makedirs('graph', exist_ok=True)

topk = 10

def construct_graph(features, label, method):
    fname = 'graph/mtab_processed_graph.txt'  # ğŸ”§ ä¿®æ­£æ–‡ä»¶å
    num = len(label)

    dist = None
    
    # ğŸ”§ ä¿®å¤ç›¸ä¼¼åº¦è®¡ç®—æ–¹æ³•
    if method == 'heat':
        dist = -0.5 * pair(features, metric='euclidean') ** 2
        sigma = np.std(dist)
        dist = np.exp(dist / (2 * sigma ** 2))

    elif method == 'cos':
        # ä½™å¼¦ç›¸ä¼¼åº¦
        from sklearn.metrics.pairwise import cosine_similarity
        dist = cosine_similarity(features)

    elif method == 'ncos':
        # å½’ä¸€åŒ–ä½™å¼¦ç›¸ä¼¼åº¦
        features_norm = normalize(features, axis=1, norm='l2')
        dist = np.dot(features_norm, features_norm.T)

    elif method == 'p':
        # Pearsonç›¸å…³ç³»æ•° - ğŸ”§ ä¿®å¤è®¡ç®—æ–¹æ³•
        from sklearn.preprocessing import StandardScaler
        scaler = StandardScaler()
        features_scaled = scaler.fit_transform(features)
        dist = np.corrcoef(features_scaled)
        # å¤„ç†NaNå€¼
        dist = np.nan_to_num(dist, nan=0.0)

    # ğŸ”§ æ·»åŠ æ•°å€¼ç¨³å®šæ€§æ£€æŸ¥
    if np.any(np.isnan(dist)) or np.any(np.isinf(dist)):
        print("âš ï¸ è·ç¦»çŸ©é˜µåŒ…å«NaNæˆ–Infï¼Œè¿›è¡Œä¿®å¤...")
        dist = np.nan_to_num(dist, nan=0.0, posinf=1.0, neginf=0.0)
    
    # ç¡®ä¿å¯¹è§’çº¿ä¸ºæœ€å¤§å€¼ï¼ˆè‡ªç›¸ä¼¼åº¦ï¼‰
    np.fill_diagonal(dist, np.max(dist))
    
    print(f"è·ç¦»çŸ©é˜µç»Ÿè®¡: min={np.min(dist):.4f}, max={np.max(dist):.4f}, mean={np.mean(dist):.4f}")

    # ğŸ”§ æ”¹è¿›KNNå›¾æ„å»º
    inds = []
    for i in range(dist.shape[0]):
        # è·å–top-kæœ€ç›¸ä¼¼çš„é‚»å±…ï¼ˆåŒ…æ‹¬è‡ªå·±ï¼‰
        ind = np.argpartition(dist[i, :], -(topk + 1))[-(topk + 1):]
        # æŒ‰ç›¸ä¼¼åº¦æ’åº
        ind = ind[np.argsort(-dist[i, ind])]
        inds.append(ind)

    # å†™å…¥å›¾æ–‡ä»¶
    with open(fname, 'w') as f:
        counter = 0
        total_edges = 0
        
        for i, neighbors in enumerate(inds):
            for neighbor in neighbors:
                if neighbor != i:  # æ’é™¤è‡ªç¯
                    if label[neighbor] != label[i]:
                        counter += 1
                    f.write(f'{i} {neighbor}\n')
                    total_edges += 1
    
    error_rate = counter / total_edges if total_edges > 0 else 0
    print(f'KNNå›¾æ„å»ºå®Œæˆ:')
    print(f'  - æ€»è¾¹æ•°: {total_edges}')
    print(f'  - é”™è¯¯è¾¹æ•°: {counter}')
    print(f'  - é”™è¯¯ç‡: {error_rate:.4f}')
    print(f'  - æ–‡ä»¶ä¿å­˜è‡³: {fname}')

def main():
    # ğŸ”§ ä½¿ç”¨é¢„å¤„ç†åçš„æ•°æ®æ–‡ä»¶
    data_file = 'data/mtab_processed.txt'
    label_file = 'data/mtab_processed_label.txt'
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(data_file):
        print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_file}")
        print("è¯·å…ˆè¿è¡Œ python preprocess_mtab.py")
        return
    
    if not os.path.exists(label_file):
        print(f"âŒ æ ‡ç­¾æ–‡ä»¶ä¸å­˜åœ¨: {label_file}")
        print("è¯·å…ˆè¿è¡Œ python preprocess_mtab.py") 
        return

    print("ğŸ“– è¯»å–é¢„å¤„ç†æ•°æ®...")
    features = np.loadtxt(data_file, dtype=float)
    labels = np.loadtxt(label_file, dtype=int)
    
    print(f"æ•°æ®ç»´åº¦: {features.shape}")
    print(f"æ ‡ç­¾æ•°: {len(np.unique(labels))}")
    print(f"æ ‡ç­¾åˆ†å¸ƒ: {np.bincount(labels)}")
    
    # ğŸ”§ å°è¯•ä¸åŒçš„ç›¸ä¼¼åº¦è®¡ç®—æ–¹æ³•
    methods = ['p', 'cos', 'ncos', 'heat']  # Pearsonæ•ˆæœé€šå¸¸æœ€å¥½
    method_names = ['Pearson', 'Cosine', 'Normalized Cosine', 'Heat Kernel']
    
    print("\nğŸ” æµ‹è¯•ä¸åŒç›¸ä¼¼åº¦æ–¹æ³•çš„é”™è¯¯ç‡:")
    for method, name in zip(methods, method_names):
        print(f"\n--- {name} æ–¹æ³• ---")
        try:
            construct_graph(features, labels, method)
        except Exception as e:
            print(f"âŒ {name} æ–¹æ³•å¤±è´¥: {e}")
    
    print(f"\nâœ… æ¨èä½¿ç”¨ Pearson æ–¹æ³•æ„å»ºçš„å›¾æ–‡ä»¶")

if __name__ == "__main__":
    main()