#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¿«é€Ÿä¿®å¤è„šæœ¬
è§£å†³æ¨¡å—å¯¼å…¥é—®é¢˜ï¼Œåˆ›å»ºç¼ºå¤±æ–‡ä»¶
"""

import os
from pathlib import Path

def create_missing_files():
    """åˆ›å»ºç¼ºå¤±çš„æ–‡ä»¶"""
    
    print("ðŸ”§ å¿«é€Ÿä¿®å¤ï¼šåˆ›å»ºç¼ºå¤±æ–‡ä»¶...")
    
    # 1. åˆ›å»ºç›®å½•ç»“æž„
    directories = ['core', 'algorithms', 'utils', 'data', 'results', 'logs', 'cache']
    for dir_name in directories:
        Path(dir_name).mkdir(exist_ok=True)
        print(f"  âœ… ç›®å½•: {dir_name}")
    
    # 2. åˆ›å»º __init__.py æ–‡ä»¶
    init_files = {
        'core/__init__.py': '',
        'algorithms/__init__.py': '',
        'utils/__init__.py': ''
    }
    
    for file_path, content in init_files.items():
        Path(file_path).touch()
        print(f"  âœ… æ–‡ä»¶: {file_path}")
    
    # 3. åˆ›å»ºç®€åŒ–çš„ utils æ¨¡å—æ–‡ä»¶
    utils_files = {
        'utils/data_loader.py': '''#!/usr/bin/env python3
"""ç®€åŒ–æ•°æ®åŠ è½½å™¨"""
import numpy as np
import pandas as pd
from pathlib import Path

class DataLoader:
    def __init__(self, config=None):
        self.config = config
    
    def load_dataset(self, data_path, labels_path=None):
        X = pd.read_csv(data_path, header=None).values
        y_true = None
        if labels_path and Path(labels_path).exists():
            y_true = pd.read_csv(labels_path, header=None).values.squeeze()
        return X, y_true
    
    def load_datasets_config(self, config_path):
        import json
        with open(config_path, 'r') as f:
            return json.load(f)
''',
        
        'utils/metrics.py': '''#!/usr/bin/env python3
"""ç®€åŒ–æŒ‡æ ‡è®¡ç®—å™¨"""
import numpy as np
from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score, silhouette_score

class MetricsCalculator:
    def calculate_all_metrics(self, y_true, y_pred, X):
        metrics = {}
        try:
            metrics['nmi'] = normalized_mutual_info_score(y_true, y_pred)
            metrics['ari'] = adjusted_rand_score(y_true, y_pred)
            metrics['silhouette'] = silhouette_score(X, y_pred)
        except:
            metrics = {'nmi': 0.0, 'ari': 0.0, 'silhouette': 0.0}
        return metrics
''',
        
        'utils/visualization.py': '''#!/usr/bin/env python3
"""ç®€åŒ–å¯è§†åŒ–å·¥å…·"""
import matplotlib.pyplot as plt

class ResultVisualizer:
    def __init__(self, config=None):
        self.config = config
    
    def plot_learning_trajectory(self, result):
        trajectory = result.get('learning_trajectory', [])
        if not trajectory:
            print("æ— å­¦ä¹ è½¨è¿¹æ•°æ®")
            return
        
        iterations = [step['iteration'] for step in trajectory]
        nmi_scores = [step['nmi'] for step in trajectory]
        
        plt.figure(figsize=(10, 6))
        plt.plot(iterations, nmi_scores, 'o-', linewidth=2, markersize=8)
        plt.xlabel('è¿­ä»£æ¬¡æ•°')
        plt.ylabel('NMI å¾—åˆ†')
        plt.title('å­¦ä¹ è½¨è¿¹ï¼šNMIæ€§èƒ½å˜åŒ–')
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.show()
'''
    }
    
    for file_path, content in utils_files.items():
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)
        print(f"  âœ… æ–‡ä»¶: {file_path}")
    
    # 4. åˆ›å»ºç®€åŒ–çš„ç®—æ³•æ–‡ä»¶
    algorithm_files = {
        'algorithms/boundary_failure.py': '''#!/usr/bin/env python3
"""ç®€åŒ–è¾¹ç•Œå¤±è´¥å­¦ä¹ """
import numpy as np
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.mixture import GaussianMixture

class BoundaryFailureLearning:
    def __init__(self, config=None):
        self.config = config
    
    def fit_predict(self, X, strategy):
        n_clusters = strategy.get('n_clusters', 3)
        pca_components = strategy.get('pca_components', 20)
        random_state = strategy.get('random_state', 42)
        
        if pca_components > 0 and pca_components < X.shape[1]:
            pca = PCA(n_components=pca_components, random_state=random_state)
            X_reduced = pca.fit_transform(X)
        else:
            X_reduced = X
        
        gmm = GaussianMixture(n_components=n_clusters, covariance_type='full', 
                             random_state=random_state, n_init=10)
        return gmm.fit_predict(X_reduced)
''',
        
        'algorithms/enhanced_sre.py': '''#!/usr/bin/env python3
"""ç®€åŒ–å¢žå¼ºSRE"""
import numpy as np
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA

class EnhancedSRE:
    def __init__(self, config=None):
        self.config = config
    
    def fit_predict(self, X, strategy):
        n_clusters = strategy.get('n_clusters', 3)
        pca_components = strategy.get('pca_components', 30)
        random_state = strategy.get('random_state', 42)
        
        if pca_components > 0 and pca_components < X.shape[1]:
            pca = PCA(n_components=pca_components, random_state=random_state)
            X_reduced = pca.fit_transform(X)
        else:
            X_reduced = X
        
        kmeans = KMeans(n_clusters=n_clusters, random_state=random_state, n_init=20)
        return kmeans.fit_predict(X_reduced)
''',
        
        'algorithms/ultimate_fusion.py': '''#!/usr/bin/env python3
"""ç®€åŒ–ç»ˆæžèžåˆ"""
import numpy as np
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.mixture import GaussianMixture

class UltimateFusion:
    def __init__(self, config=None):
        self.config = config
    
    def fit_predict(self, X, strategy):
        n_clusters = strategy.get('n_clusters', 3)
        pca_components = strategy.get('pca_components', 50)
        random_state = strategy.get('random_state', 42)
        
        if pca_components > 0 and pca_components < X.shape[1]:
            pca = PCA(n_components=pca_components, random_state=random_state)
            X_reduced = pca.fit_transform(X)
        else:
            X_reduced = X
        
        # ç®€åŒ–ç‰ˆï¼šåªç”¨GMM
        gmm = GaussianMixture(n_components=n_clusters, covariance_type='tied', 
                             random_state=random_state)
        return gmm.fit_predict(X_reduced)
'''
    }
    
    for file_path, content in algorithm_files.items():
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)
        print(f"  âœ… æ–‡ä»¶: {file_path}")
    
    print("\nðŸŽ‰ å¿«é€Ÿä¿®å¤å®Œæˆ!")
    print("ðŸ“ çŽ°åœ¨å¯ä»¥é‡æ–°è¿è¡Œ main.py äº†")

def check_dependencies():
    """æ£€æŸ¥ä¾èµ–åŒ…"""
    print("\nðŸ” æ£€æŸ¥ä¾èµ–åŒ…...")
    
    required_packages = [
        'numpy', 'pandas', 'scikit-learn', 'matplotlib', 'scipy'
    ]
    
    missing_packages = []
    
    for package in required_packages:
        try:
            __import__(package.replace('-', '_'))
            print(f"  âœ… {package}")
        except ImportError:
            print(f"  âŒ {package} - æœªå®‰è£…")
            missing_packages.append(package)
    
    if missing_packages:
        print(f"\nðŸ“¦ éœ€è¦å®‰è£…ç¼ºå¤±çš„åŒ…:")
        print(f"pip install {' '.join(missing_packages)}")
    else:
        print(f"\nðŸŽ‰ æ‰€æœ‰ä¾èµ–åŒ…éƒ½å·²å®‰è£…!")

def test_basic_functionality():
    """æµ‹è¯•åŸºæœ¬åŠŸèƒ½"""
    print("\nðŸ§ª æµ‹è¯•åŸºæœ¬åŠŸèƒ½...")
    
    try:
        # æµ‹è¯•æ•°æ®ç”Ÿæˆ
        from sklearn.datasets import make_blobs
        import numpy as np
        
        X, y = make_blobs(n_samples=100, centers=3, n_features=10, random_state=42)
        print(f"  âœ… æµ‹è¯•æ•°æ®ç”Ÿæˆ: {X.shape}")
        
        # æµ‹è¯•å‡ ä½•åˆ†æžå™¨
        if Path('core/geometry_analyzer.py').exists():
            from core.geometry_analyzer import GeometryAnalyzer
            analyzer = GeometryAnalyzer()
            features = analyzer.analyze(X, verbose=False)
            print(f"  âœ… å‡ ä½•åˆ†æžå™¨è¿è¡Œæ­£å¸¸")
        
        print(f"\nðŸŽ‰ åŸºæœ¬åŠŸèƒ½æµ‹è¯•é€šè¿‡!")
        
    except Exception as e:
        print(f"  âŒ æµ‹è¯•å¤±è´¥: {e}")

if __name__ == "__main__":
    print("ðŸš€ æ™ºèƒ½scRNAç³»ç»Ÿå¿«é€Ÿä¿®å¤å·¥å…·")
    print("=" * 50)
    
    # 1. åˆ›å»ºç¼ºå¤±æ–‡ä»¶
    create_missing_files()
    
    # 2. æ£€æŸ¥ä¾èµ–
    check_dependencies()
    
    # 3. æµ‹è¯•åŠŸèƒ½
    test_basic_functionality()
    
    print("\n" + "=" * 50)
    print("ðŸŽ¯ ä¿®å¤å®Œæˆ! çŽ°åœ¨å¯ä»¥è¿è¡Œ:")
    print("python main.py --data in_X.csv --labels true_labs.csv --name Usoskin")
